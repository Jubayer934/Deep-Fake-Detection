{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1ct55it4oSOpNGUPH1NZ5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Connecting to Drive"],"metadata":{"id":"mCp1sZqym4Od"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3qOl01HsmuWF","executionInfo":{"status":"ok","timestamp":1748635667533,"user_tz":-360,"elapsed":43473,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"9d861114-6739-4762-8a93-a05357cb9914"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","# Path to the zip file in Drive\n","zip_path = \"/content/drive/MyDrive/ModelTrain/DFD/Dataset/DFD.zip\"\n","\n","# Unzip it to /content/\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(\"/content/deepfake_dataset\")\n","\n","# Set dataset path\n","dataset_path = \"/content/deepfake_dataset\""],"metadata":{"id":"nPhgbgKYnTb3","executionInfo":{"status":"ok","timestamp":1748635777069,"user_tz":-360,"elapsed":10126,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# List top-level files/folders\n","print(os.listdir(\"/content/deepfake_dataset\"))\n","\n","# If it's nested, explore further:\n","for root, dirs, files in os.walk(\"/content/deepfake_dataset\"):\n","    print(\"Root:\", root)\n","    print(\"Dirs:\", dirs)\n","    print(\"Files:\", files[:5])  # just print the first 5 files\n","    print(\"===\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4AvLbWPoEgJ","executionInfo":{"status":"ok","timestamp":1748635795305,"user_tz":-360,"elapsed":7,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"789c1af1-0cd9-4a29-edf2-d2e33f6e3997"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['DFD']\n","Root: /content/deepfake_dataset\n","Dirs: ['DFD']\n","Files: []\n","===\n","Root: /content/deepfake_dataset/DFD\n","Dirs: ['DFD_manipulated_sequences', 'DFD_original sequences']\n","Files: []\n","===\n","Root: /content/deepfake_dataset/DFD/DFD_manipulated_sequences\n","Dirs: []\n","Files: ['01_09__talking_angry_couch__O8HNNX43.mp4', '01_04__walking_outside_cafe_disgusted__0XUW13RW.mp4', '01_11__talking_against_wall__9229VVZ3.mp4', '01_03__meeting_serious__JZUXXFRB.mp4', '01_15__walking_down_street_outside_angry__02HILKYO.mp4']\n","===\n","Root: /content/deepfake_dataset/DFD/DFD_original sequences\n","Dirs: []\n","Files: ['01__exit_phone_room.mp4', '01__outside_talking_still_laughing.mp4', '01__hugging_happy.mp4', '01__kitchen_pan.mp4', '01__outside_talking_pan_laughing.mp4']\n","===\n"]}]},{"cell_type":"markdown","source":[" ## Module Imports"],"metadata":{"id":"qVSYC7fUormg"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical"],"metadata":{"id":"O-ActHKIo0Mp","executionInfo":{"status":"ok","timestamp":1748635805146,"user_tz":-360,"elapsed":3611,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","if tf.config.list_physical_devices('GPU'):\n","    print(\"✅ GPU is available:\", tf.config.list_physical_devices('GPU'))\n","else:\n","    print(\"❌ GPU not available.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcK2XV0VpCTN","executionInfo":{"status":"ok","timestamp":1748635805156,"user_tz":-360,"elapsed":6,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"6be35596-a246-4185-8864-1bf0c34b3b4a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["❌ GPU not available.\n"]}]},{"cell_type":"markdown","source":["## Function to extract frames from a video"],"metadata":{"id":"4J1499zApUDx"}},{"cell_type":"code","source":["REAL_PATH = \"/content/deepfake_dataset/DFD/DFD_original sequences\"\n","FAKE_PATH = \"/content/deepfake_dataset/DFD/DFD_manipulated_sequences\""],"metadata":{"id":"Dnjb9iwqpIMT","executionInfo":{"status":"ok","timestamp":1748635806096,"user_tz":-360,"elapsed":3,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["OUTPUT_FRAME_SIZE = (128, 128)  # Frame dimensions\n","FRAME_COUNT = 10  # Number of frames to extract per video\n","\n","# Function to extract frames from a video\n","def extract_frames(video_path, output_size=(128, 128), frame_count=10):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    step = max(total_frames // frame_count, 1)  # Uniform sampling\n","\n","    for i in range(frame_count):\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, output_size)\n","        frames.append(frame)\n","    cap.release()\n","    return np.array(frames)"],"metadata":{"id":"KSnRrzcLpcA2","executionInfo":{"status":"ok","timestamp":1748635807844,"user_tz":-360,"elapsed":6,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Prepare data and labels\n","data = []\n","labels = []\n","\n","# Process real videos\n","print(\"Processing real videos...\")\n","for video_file in tqdm(os.listdir(REAL_PATH)):\n","    video_path = os.path.join(REAL_PATH, video_file)\n","    frames = extract_frames(video_path, output_size=OUTPUT_FRAME_SIZE, frame_count=FRAME_COUNT)\n","    if len(frames) == FRAME_COUNT:  # Ensure correct frame count\n","        data.append(frames)\n","        labels.append(0)  # Label 0 for real"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-V2vZGsxq1HN","outputId":"db4a7fa0-a215-45a4-bef3-d849ad32c397","executionInfo":{"status":"ok","timestamp":1748635865835,"user_tz":-360,"elapsed":55697,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing real videos...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:55<00:00,  5.57s/it]\n"]}]},{"cell_type":"code","source":["# Process fake videos\n","print(\"Processing fake videos...\")\n","for video_file in tqdm(os.listdir(FAKE_PATH)):\n","    video_path = os.path.join(FAKE_PATH, video_file)\n","    frames = extract_frames(video_path, output_size=OUTPUT_FRAME_SIZE, frame_count=FRAME_COUNT)\n","    if len(frames) == FRAME_COUNT:\n","        data.append(frames)\n","        labels.append(1)  # Label 1 for fake"],"metadata":{"id":"npgvpLkhrm_n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748636410871,"user_tz":-360,"elapsed":540745,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"a999ff84-0458-48ab-bd78-5f82bdc416ef"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing fake videos...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [09:00<00:00,  5.41s/it]\n"]}]},{"cell_type":"code","source":["# Convert to numpy arrays\n","data = np.array(data)  # Shape: (num_videos, num_frames, 128, 128, 3)\n","labels = np.array(labels)"],"metadata":{"id":"07ijHpNQrpm_","executionInfo":{"status":"ok","timestamp":1748636848721,"user_tz":-360,"elapsed":101,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"neqkUSk-4ONT","executionInfo":{"status":"ok","timestamp":1748636901531,"user_tz":-360,"elapsed":6,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"f957ae1a-8de5-412d-ac1a-f74cfc7f2f16"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"]}]},{"cell_type":"code","source":["print(\"Data shape:\", data.shape)       # Should be (num_videos, num_frames, 128, 128, 3)\n","print(\"Labels shape:\", labels.shape)   # Should be (num_videos,)\n","print(\"Data type:\", data.dtype)\n","print(\"Labels type:\", labels.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOraxDYr4apd","executionInfo":{"status":"ok","timestamp":1748636914460,"user_tz":-360,"elapsed":43,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"441cd233-712f-4cee-f915-fa38ff747d68"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Data shape: (110, 10, 128, 128, 3)\n","Labels shape: (110,)\n","Data type: uint8\n","Labels type: int64\n"]}]},{"cell_type":"markdown","source":["## Spliting Dataset: 60% train, 20% test, 20% validation"],"metadata":{"id":"nhqT3WDM5U_v"}},{"cell_type":"code","source":["# Split into train, validation, and test sets\n","X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.4, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"],"metadata":{"id":"EGEU4faN4hpi","executionInfo":{"status":"ok","timestamp":1748637074483,"user_tz":-360,"elapsed":79,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Normalize data\n","X_train = X_train / 255.0\n","X_val = X_val / 255.0\n","X_test = X_test / 255.0"],"metadata":{"id":"goiW2PNE5UPt","executionInfo":{"status":"ok","timestamp":1748637205543,"user_tz":-360,"elapsed":401,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## One-hot encoded"],"metadata":{"id":"EpRjVEwi50rq"}},{"cell_type":"code","source":["# Convert labels to categorical\n","y_train = to_categorical(y_train, num_classes=2) # for real [1,0]  and   fake [0,1]\n","y_val = to_categorical(y_val, num_classes=2)\n","y_test = to_categorical(y_test, num_classes=2)"],"metadata":{"id":"PvjcEaYB5k3k","executionInfo":{"status":"ok","timestamp":1748637343672,"user_tz":-360,"elapsed":4,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["print(f\"Data shapes: Train - {X_train.shape}, Validation - {X_val.shape}, Test - {X_test.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9UVwXcT46Geb","executionInfo":{"status":"ok","timestamp":1748637364021,"user_tz":-360,"elapsed":43,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"155a2cc8-78f5-423e-c652-21ec234b7367"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Data shapes: Train - (66, 10, 128, 128, 3), Validation - (22, 10, 128, 128, 3), Test - (22, 10, 128, 128, 3)\n"]}]},{"cell_type":"markdown","source":["## Augment frames to avoit overfitting"],"metadata":{"id":"bjNdDMEa6xj_"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"metadata":{"id":"qhdNz8RV6N1Y","executionInfo":{"status":"ok","timestamp":1748637532810,"user_tz":-360,"elapsed":40,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Augment frames\n","datagen = ImageDataGenerator(\n","    horizontal_flip=True,\n","    rotation_range=10,\n","    zoom_range=0.1,\n","    brightness_range=[0.8, 1.2]\n",")"],"metadata":{"id":"ZgjWCpYB603c","executionInfo":{"status":"ok","timestamp":1748637544672,"user_tz":-360,"elapsed":47,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Function to augment extracted frames\n","def augment_frames(frames):\n","    augmented_frames = []  # Create an empty list to store augmented frames\n","    for frame in frames:\n","        frame = datagen.random_transform(frame)  # Apply random augmentation\n","        augmented_frames.append(frame)  # Add the augmented frame to the list\n","    return np.array(augmented_frames)  # Return as a NumPy array"],"metadata":{"id":"jEZscfuL7FoY","executionInfo":{"status":"ok","timestamp":1748637614839,"user_tz":-360,"elapsed":48,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["augmented_data = []  # List to store augmented frames\n","augmented_labels = []  # List to store augmented labels\n","\n","for i in range(len(X_train)):  # Loop through each video in training data\n","    augmented_frames = augment_frames(X_train[i])  # Augment frames of the video\n","    augmented_data.append(augmented_frames)  # Add the augmented frames to the list\n","    augmented_labels.append(y_train[i])  # Add the corresponding label to the list"],"metadata":{"id":"Gaag8Xxl7MCK","executionInfo":{"status":"ok","timestamp":1748637666139,"user_tz":-360,"elapsed":3143,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Combine original and augmented data\n","X_train_augmented = np.concatenate((X_train, np.array(augmented_data)))\n","y_train_augmented = np.concatenate((y_train, np.array(augmented_labels)))"],"metadata":{"id":"-KWZYKdT7Xcu","executionInfo":{"status":"ok","timestamp":1748637708834,"user_tz":-360,"elapsed":133,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["print(f\"Augmented Train Data: {X_train_augmented.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sC2_2RtX7fsU","executionInfo":{"status":"ok","timestamp":1748637721365,"user_tz":-360,"elapsed":43,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"3ef20fca-6333-49f8-d98d-b71dc9d97154"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Augmented Train Data: (132, 10, 128, 128, 3)\n"]}]},{"cell_type":"markdown","source":["## Training Dataset"],"metadata":{"id":"DSFaFQcZ9Msv"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import Xception\n","from tensorflow.keras.layers import Dense, Flatten, TimeDistributed, LSTM\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dropout"],"metadata":{"id":"kVUdekSN7jLN","executionInfo":{"status":"ok","timestamp":1748637736441,"user_tz":-360,"elapsed":17,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def build_improved_model(input_shape=(FRAME_COUNT, 128, 128, 3)):\n","    model = Sequential([\n","        TimeDistributed(Xception(weights='imagenet', include_top=False, input_shape=(128, 128, 3))),\n","        TimeDistributed(Flatten()),\n","        Dropout(0.5),  # Add dropout for regularization\n","        LSTM(128, return_sequences=False),\n","        Dropout(0.5),  # Add dropout\n","        Dense(64, activation='relu'),\n","        Dense(2, activation='softmax')\n","    ])\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model"],"metadata":{"id":"MAuJNDtC9KzS","executionInfo":{"status":"ok","timestamp":1748638152250,"user_tz":-360,"elapsed":7,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["model = build_improved_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T78cGsvX9L2p","executionInfo":{"status":"ok","timestamp":1748638187749,"user_tz":-360,"elapsed":5443,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"47a44d1d-03a9-4c2a-e5bb-8832a8e3a9c6"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"a8j4eYrY9UVl","executionInfo":{"status":"ok","timestamp":1748638198896,"user_tz":-360,"elapsed":38,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"aff1b676-c03e-442d-9dd8-1f54d77bf80a"},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ time_distributed                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ time_distributed_1              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ time_distributed                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ time_distributed_1              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,861,480\u001b[0m (79.58 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> (79.58 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,806,952\u001b[0m (79.37 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,806,952</span> (79.37 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m54,528\u001b[0m (213.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,528</span> (213.00 KB)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","\n","checkpoint_path = '/content/drive/MyDrive/ModelTrain/DFD/Model/deepfake_detection_model.keras'  # Save to Drive\n","\n","checkpoint = ModelCheckpoint(\n","    checkpoint_path,          # File path to save the model\n","    monitor=\"val_accuracy\",   # Monitor validation accuracy during training\n","    save_best_only=True,      # Only save model when val_accuracy improves\n","    verbose=1                # Print a message when model is saved\n",")\n"],"metadata":{"id":"g4_VySCF9YEL","executionInfo":{"status":"ok","timestamp":1748638377350,"user_tz":-360,"elapsed":40,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["lr_scheduler = ReduceLROnPlateau(\n","    monitor=\"val_loss\",  # Watch validation loss\n","    factor=0.5,          # Reduce learning rate by half when triggered\n","    patience=3,          # Wait 3 epochs with no improvement before reducing\n","    verbose=1            # Print a message when learning rate is reduced\n",")"],"metadata":{"id":"px8KqfzY-tTR","executionInfo":{"status":"ok","timestamp":1748638557964,"user_tz":-360,"elapsed":4,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","history = model.fit(\n","    X_train_augmented, y_train_augmented,\n","    validation_data=(X_val, y_val),\n","    epochs=50,\n","    batch_size=10,\n","    callbacks=[checkpoint, lr_scheduler]\n",")\n","model.save(\"deepfake_detection_model.keras\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530},"id":"7c0sUjP4-1U3","executionInfo":{"status":"error","timestamp":1748639316977,"user_tz":-360,"elapsed":718209,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"43a0df80-6c0f-4619-f670-88d7b740a5c0"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.7577 - loss: 0.4994 \n","Epoch 1: val_accuracy improved from -inf to 0.86364, saving model to /content/drive/MyDrive/ModelTrain/DFD/Model/deepfake_detection_model.keras\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 18s/step - accuracy: 0.7638 - loss: 0.5025 - val_accuracy: 0.8636 - val_loss: 0.7898 - learning_rate: 1.0000e-04\n","Epoch 2/50\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - accuracy: 0.9312 - loss: 0.2732 \n","Epoch 2: val_accuracy did not improve from 0.86364\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 19s/step - accuracy: 0.9297 - loss: 0.2768 - val_accuracy: 0.8636 - val_loss: 0.8050 - learning_rate: 1.0000e-04\n","Epoch 3/50\n","\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:30\u001b[0m 21s/step - accuracy: 0.8000 - loss: 0.4542"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-0baa92b0d9e2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX_train_augmented\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_augmented\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Accuracy Test"],"metadata":{"id":"gxFPAHuiA0Ld"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score\n","\n","# Load the best saved model\n","from tensorflow.keras.models import load_model\n","model = load_model('/content/drive/MyDrive/ModelTrain/DFD/Model/deepfake_detection_model.keras')"],"metadata":{"id":"XnUxPIUT-7MB","executionInfo":{"status":"ok","timestamp":1748639365001,"user_tz":-360,"elapsed":5244,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# Predict class probabilities on test set\n","y_pred_prob = model.predict(X_test)\n","\n","# Convert probabilities to class labels (argmax)\n","y_pred = y_pred_prob.argmax(axis=1)\n","\n","# Convert one-hot encoded test labels to class indices\n","y_true = y_test.argmax(axis=1)\n","\n","# Print accuracy\n","print(\"Test Accuracy:\", accuracy_score(y_true, y_pred))\n","\n","print(\"Classification Report:\")\n","# Print classification report (precision, recall, f1-score)\n","print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdkN2VH3A3gG","executionInfo":{"status":"ok","timestamp":1748639526721,"user_tz":-360,"elapsed":9667,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"c5d42479-bf23-4e4e-d636-eb70c37ed463"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n","Test Accuracy: 0.9545454545454546\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","        Real       0.00      0.00      0.00         1\n","        Fake       0.95      1.00      0.98        21\n","\n","    accuracy                           0.95        22\n","   macro avg       0.48      0.50      0.49        22\n","weighted avg       0.91      0.95      0.93        22\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"markdown","source":["## Real Time Test"],"metadata":{"id":"c2mzi236Gj0Z"}},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","# Load the model for real-time detection\n","loaded_model = load_model('/content/drive/MyDrive/ModelTrain/DFD/Model/deepfake_detection_model.keras')\n","\n","def predict_video(video_path, model, output_size=(128, 128), frame_count=10):\n","    frames = extract_frames(video_path, output_size, frame_count)\n","    frames = frames / 255.0  # Normalize\n","    frames = np.expand_dims(frames, axis=0)  # Add batch dimension\n","    prediction = model.predict(frames)\n","    label = \"FAKE\" if np.argmax(prediction) == 1 else \"REAL\"\n","    confidence = prediction[0][np.argmax(prediction)]\n","    print(f\"Prediction: {label} (Confidence: {confidence:.2f})\")\n","\n","# Test prediction on a video\n","real_sample_path = os.path.join('/content/drive/MyDrive/ModelTrain/DFD/Test/r.mp4')  # Replace with real video path\n","fake_sample_path = os.path.join('/content/drive/MyDrive/ModelTrain/DFD/Test/f.mp4')  # Replace with fake video path\n","\n","print(\"Real Video Prediction:\")\n","predict_video(real_sample_path, model)\n","\n","print(\"Fake Video Prediction:\")\n","predict_video(fake_sample_path, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-OpqbBsFs1M","executionInfo":{"status":"ok","timestamp":1748641200944,"user_tz":-360,"elapsed":15713,"user":{"displayName":"Jubayer- Al- Mahmud","userId":"00719257082082193821"}},"outputId":"17cc56bd-863b-4be4-b32b-4eac89a924a6"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Real Video Prediction:\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step\n","Prediction: FAKE (Confidence: 0.99)\n","Fake Video Prediction:\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630ms/step\n","Prediction: FAKE (Confidence: 0.99)\n"]}]}]}